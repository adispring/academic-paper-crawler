# AI åŠŸèƒ½ä½¿ç”¨æŒ‡å—

æœ¬é¡¹ç›®å·²é›†æˆ LangGraph SDK å’Œ OpenAI æ¨¡å‹ï¼Œæä¾›å¼ºå¤§çš„å­¦æœ¯è®ºæ–‡æ™ºèƒ½åˆ†æåŠŸèƒ½ã€‚

## åŠŸèƒ½ç‰¹æ€§

- ğŸ“ **æ™ºèƒ½æ€»ç»“**: è‡ªåŠ¨ç”Ÿæˆè®ºæ–‡æ‘˜è¦æ€»ç»“
- ğŸ·ï¸ **è‡ªåŠ¨åˆ†ç±»**: æ ¹æ®å†…å®¹å¯¹è®ºæ–‡è¿›è¡Œåˆ†ç±»
- ğŸ” **å…³é”®è¯æå–**: æå–è®ºæ–‡å…³é”®è¯
- ğŸ’­ **æƒ…æ„Ÿåˆ†æ**: åˆ†æè®ºæ–‡æ‘˜è¦çš„æƒ…æ„Ÿå€¾å‘
- â­ **ç›¸å…³æ€§è¯„åˆ†**: è¯„ä¼°è®ºæ–‡ä¸æœç´¢å…³é”®è¯çš„ç›¸å…³æ€§

## ç¯å¢ƒé…ç½®

### 1. è®¾ç½® OpenAI API å¯†é’¥

**æ–¹æ³•ä¸€ï¼šä½¿ç”¨ .env æ–‡ä»¶ï¼ˆæ¨èï¼‰**
```bash
# å¤åˆ¶é…ç½®æ¨¡æ¿
cp .env.example .env

# ç¼–è¾‘ .env æ–‡ä»¶ï¼Œè®¾ç½®æ‚¨çš„ API å¯†é’¥
# OPENAI_API_KEY=your_openai_api_key_here
```

**æ–¹æ³•äºŒï¼šç¯å¢ƒå˜é‡**
```bash
export OPENAI_API_KEY="your_openai_api_key_here"
```

**æ–¹æ³•ä¸‰ï¼šå‘½ä»¤è¡Œå‚æ•°**
```bash
node dist/index.js search -k "artificial intelligence" --ai --ai-api-key "your_key_here"
```

### 2. å¯é€‰é…ç½®
```bash
# è‡ªå®šä¹‰æ¨¡å‹
--ai-model gpt-4

# è°ƒèŠ‚åˆ›é€ æ€§ï¼ˆ0.0-2.0ï¼‰
--ai-temperature 0.5

# è®¾ç½®æœ€å¤§ä»¤ç‰Œæ•°
--ai-max-tokens 1500
```

## ä½¿ç”¨ç¤ºä¾‹

### åŸºç¡€AIåˆ†æ
```bash
# å¯ç”¨AIåˆ†æåŠŸèƒ½
npm start search -k "machine learning" --ai

# ä½¿ç”¨æŒ‡å®šæ¨¡å‹
npm start search -k "deep learning" --ai --ai-model "gpt-4"

# å®Œæ•´é…ç½®ç¤ºä¾‹
npm start search -k "natural language processing" \
  --ai \
  --ai-model "gpt-3.5-turbo" \
  --ai-temperature 0.3 \
  --ai-max-tokens 1000 \
  --ai-api-key "your_key_here"
```

### æ‰¹é‡AIåˆ†æ
```bash
# å¯¹æ‰¹é‡å…³é”®è¯å¯ç”¨AIåˆ†æ
npm start batch -f keywords.txt --ai
```

## è¾“å‡ºæ ¼å¼

### CSV è¾“å‡º
å¯ç”¨AIåˆ†æåï¼ŒCSVæ–‡ä»¶å°†åŒ…å«ä»¥ä¸‹é¢å¤–åˆ—ï¼š
- AIæ€»ç»“
- AIåˆ†ç±»
- AIå…³é”®è¯
- AIæƒ…æ„Ÿåˆ†æ
- AIç›¸å…³æ€§è¯„åˆ†
- AIæ¨¡å‹
- AIå¤„ç†æ—¶é—´

### JSON è¾“å‡º
JSONæ ¼å¼ä¼šåœ¨æ¯ä¸ªè®ºæ–‡å¯¹è±¡ä¸­åŒ…å« `aiAnalysis` å­—æ®µï¼š

```json
{
  "title": "è®ºæ–‡æ ‡é¢˜",
  "authors": ["ä½œè€…1", "ä½œè€…2"],
  "abstract": "è®ºæ–‡æ‘˜è¦",
  "aiAnalysis": {
    "summary": "AIç”Ÿæˆçš„æ€»ç»“",
    "classification": "äººå·¥æ™ºèƒ½",
    "keywords": ["æœºå™¨å­¦ä¹ ", "æ·±åº¦å­¦ä¹ "],
    "sentiment": "positive",
    "relevanceScore": 8.5,
    "model": "gpt-3.5-turbo",
    "processedAt": "2024-01-01T12:00:00.000Z"
  }
}
```

## ç¼–ç¨‹æ¥å£

### å¯ç”¨/ç¦ç”¨AIåˆ†æ
```typescript
const crawler = new AcademicPaperCrawler({
  aiConfig: {
    enabled: true,
    model: 'gpt-3.5-turbo',
    temperature: 0.3,
    maxTokens: 1000,
    analysisTypes: ['summarize', 'extract_keywords', 'relevance']
  }
});

// åŠ¨æ€å¯ç”¨/ç¦ç”¨
crawler.enableAI(true);

// æ£€æŸ¥AIæœåŠ¡å¯ç”¨æ€§
const isAvailable = await crawler.checkAIAvailability();
```

### è‡ªå®šä¹‰AIåˆ†æ
```typescript
import { createPaperAnalyzer, AIAnalysisType } from './src/ai';

const analyzer = createPaperAnalyzer({
  enabled: true,
  model: 'gpt-4',
  temperature: 0.5,
  maxTokens: 1500
});

// å•ç‹¬åˆ†æè®ºæ–‡
const result = await analyzer.analyzePaper(paperInfo, AIAnalysisType.SUMMARIZE);

// æ‰¹é‡åˆ†æ
const enhancedPapers = await analyzer.analyzeMultiplePapers(papers);
```

## æ€§èƒ½ä¼˜åŒ–

1. **é€Ÿç‡é™åˆ¶**: ç³»ç»Ÿè‡ªåŠ¨åœ¨è¯·æ±‚é—´æ·»åŠ å»¶è¿Ÿï¼Œé¿å…è§¦å‘APIé™åˆ¶
2. **é”™è¯¯é‡è¯•**: å†…ç½®é‡è¯•æœºåˆ¶ï¼Œæé«˜æˆåŠŸç‡
3. **å¹¶è¡Œå¤„ç†**: å¤šç§åˆ†æç±»å‹å¹¶è¡Œæ‰§è¡Œï¼Œæé«˜æ•ˆç‡
4. **æ™ºèƒ½ç¼“å­˜**: é¿å…é‡å¤åˆ†æç›¸åŒå†…å®¹

## æ³¨æ„äº‹é¡¹

- ç¡®ä¿æœ‰è¶³å¤Ÿçš„ OpenAI API é…é¢
- AIåˆ†æä¼šå¢åŠ å¤„ç†æ—¶é—´ï¼Œè¯·è€å¿ƒç­‰å¾…
- å»ºè®®å…ˆç”¨å°‘é‡æ•°æ®æµ‹è¯•ï¼Œå†è¿›è¡Œå¤§è§„æ¨¡å¤„ç†
- å®šæœŸæ£€æŸ¥APIä½¿ç”¨æƒ…å†µï¼Œé¿å…è¶…å‡ºé…é¢

## æ•…éšœæ’é™¤

### å¸¸è§é—®é¢˜

1. **APIå¯†é’¥é”™è¯¯**
   - æ£€æŸ¥å¯†é’¥æ˜¯å¦æ­£ç¡®è®¾ç½®
   - ç¡®è®¤å¯†é’¥æœ‰æ•ˆæœŸå’Œæƒé™

2. **ç½‘ç»œè¿æ¥é—®é¢˜**
   - æ£€æŸ¥ç½‘ç»œè¿æ¥
   - è€ƒè™‘ä½¿ç”¨ä»£ç†

3. **é…é¢ä¸è¶³**
   - æ£€æŸ¥APIä½¿ç”¨æƒ…å†µ
   - è€ƒè™‘å‡çº§è´¦æˆ·è®¡åˆ’

### è°ƒè¯•æ¨¡å¼
```bash
# å¯ç”¨è¯¦ç»†æ—¥å¿—
DEBUG=true npm start search -k "test" --ai
```

é€šè¿‡è¿™äº›åŠŸèƒ½ï¼Œæ‚¨å¯ä»¥è·å¾—æ›´æ·±å…¥ã€æ›´æ™ºèƒ½çš„å­¦æœ¯è®ºæ–‡åˆ†æç»“æœï¼ 